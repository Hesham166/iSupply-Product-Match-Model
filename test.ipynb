{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Direct Prediction from xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/checkpoint_epoch_15.pth\n",
      "Loaded master and test data from Excel files.\n",
      "Data cleaning completed.\n",
      "Model start...\n",
      "Model done finding most similar candidates.\n",
      "DataFrame saved successfully to new file ./validation_output.xlsx in sheet 'validation_output'.\n",
      "Predictions saved to ./validation_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "p = Predictor()\n",
    "\n",
    "output_df = p.predict_from_excel(\n",
    "    master_xlsx_path='./data/raw/Product Matching Dataset.xlsx',\n",
    "    test_xlsx_path='./data/preprocessed/validation_dataset.xlsx',\n",
    "    output_xlsx_path='./validation_output.xlsx',\n",
    "    master_sheet='Master File',\n",
    "    test_sheet=\"validation_data\",\n",
    "    output_sheet_name=\"validation_output\",\n",
    "    query_names_column='seller_item_name',\n",
    "    query_prices_column='price',\n",
    "    master_candidate_names_column='product_name_ar',\n",
    "    master_prices_column='price',\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score : 0.985361653272101\n",
      "Recall Score    : 0.985361653272101\n",
      "F1 Score        : 0.985361653272101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Measures of the top 1 candidate is the correct one,\n",
    "# it doesn't account for 2nd and 3rd place.\n",
    "print(f\"Precision Score : {precision_score(output_df['sku'], output_df['sku1'], average='micro')}\")\n",
    "print(f\"Recall Score    : {recall_score(output_df['sku'], output_df['sku1'], average='micro')}\")\n",
    "print(f\"F1 Score        : {f1_score(output_df['sku'], output_df['sku1'], average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Manual loading and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predictor import Predictor\n",
    "import pandas as pd\n",
    "from src.utils import add_top_k_scores_to_df, save_dataframe_to_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('./data/preprocessed/validation_dataset.csv')\n",
    "master_file = pd.read_csv('./data/preprocessed/master_file.csv')\n",
    "\n",
    "queries, query_prices = valid_df['seller_item_name'], valid_df['price']\n",
    "candidates, candidate_prices = master_file['product_name_ar'], master_file['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/checkpoint_epoch_15.pth\n"
     ]
    }
   ],
   "source": [
    "p = Predictor()\n",
    "\n",
    "scores = [p.candidate_ranking(\n",
    "    query, candidates, query_prices[idx],\n",
    "    candidate_prices, sort=True\n",
    ") for idx, query in enumerate(queries)]         # shape: (queries num, candidates num, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = add_top_k_scores_to_df(valid_df, scores, master_file, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score : 0.985361653272101\n",
      "Recall Score    : 0.985361653272101\n",
      "F1 Score        : 0.985361653272101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Measures of the top 1 candidate is the correct one, doesn't account for 2nd and 3rd place.\n",
    "print(f\"Precision Score : {precision_score(valid_df['sku'], valid_df['sku1'], average='micro')}\")\n",
    "print(f\"Recall Score    : {recall_score(valid_df['sku'], valid_df['sku1'], average='micro')}\")\n",
    "print(f\"F1 Score        : {f1_score(valid_df['sku'], valid_df['sku1'], average='micro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct candidate not in top three: 27\n"
     ]
    }
   ],
   "source": [
    "# all the example where the correct one is not in the top 3\n",
    "not_in_top3 = valid_df[(valid_df['sku'] != valid_df['sku1']) & (valid_df['sku'] != valid_df['sku2']) & (valid_df['sku'] != valid_df['sku3'])]\n",
    "\n",
    "print(f\"Correct candidate not in top three: {not_in_top3.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved successfully to ./validation_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "save_dataframe_to_xlsx(\n",
    "    df=valid_df,\n",
    "    file_path='./validation_output.xlsx',\n",
    "    sheet_name='Results'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
